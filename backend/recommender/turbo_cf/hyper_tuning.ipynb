{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f038e3f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import scipy.sparse as sp\n",
    "\n",
    "def recall_at_k(gt_mat, results, k=20):\n",
    "    recall_sum = 0\n",
    "    num_users = gt_mat.shape[0]\n",
    "    valid_users = 0\n",
    "\n",
    "    # Verificamos si es rala para usar el acceso r谩pido, si no, usamos numpy est谩ndar\n",
    "    is_sparse = sp.issparse(gt_mat)\n",
    "    if is_sparse:\n",
    "        gt_mat = gt_mat.tolil()\n",
    "\n",
    "    for i in range(num_users):\n",
    "        if is_sparse:\n",
    "            relevant_items = gt_mat.rows[i]\n",
    "        else:\n",
    "            relevant_items = np.where(gt_mat[i, :] > 0)[0]\n",
    "            \n",
    "        if len(relevant_items) == 0:\n",
    "            continue\n",
    "            \n",
    "        valid_users += 1\n",
    "        top_predicted_items = results[i, :k]\n",
    "        \n",
    "        hits = len(set(relevant_items).intersection(set(top_predicted_items)))\n",
    "        recall_sum += hits / len(relevant_items)\n",
    "        \n",
    "    return recall_sum / valid_users if valid_users > 0 else 0\n",
    "\n",
    "\n",
    "def ndcg_at_k(gt_mat, results, k=20):\n",
    "    ndcg_sum = 0\n",
    "    num_users = gt_mat.shape[0]\n",
    "    valid_users = 0\n",
    "\n",
    "    is_sparse = sp.issparse(gt_mat)\n",
    "    if is_sparse:\n",
    "        gt_mat = gt_mat.tolil()\n",
    "\n",
    "    for i in range(num_users):\n",
    "        if is_sparse:\n",
    "            relevant_items = set(gt_mat.rows[i])\n",
    "        else:\n",
    "            relevant_items = set(np.where(gt_mat[i, :] > 0)[0])\n",
    "\n",
    "        if len(relevant_items) == 0:\n",
    "            continue\n",
    "            \n",
    "        valid_users += 1\n",
    "        top_predicted_items = results[i, :k]\n",
    "        \n",
    "        dcg = 0\n",
    "        idcg = 0\n",
    "        \n",
    "        for j, item in enumerate(top_predicted_items):\n",
    "            if item in relevant_items:\n",
    "                dcg += 1 / np.log2(j + 2)\n",
    "        \n",
    "        for j in range(min(len(relevant_items), k)):\n",
    "            idcg += 1 / np.log2(j + 2)\n",
    "            \n",
    "        if idcg > 0:\n",
    "            ndcg_sum += dcg / idcg\n",
    "            \n",
    "    return ndcg_sum / valid_users if valid_users > 0 else 0\n",
    "\n",
    "\n",
    "def csr2torch(csr_matrix):\n",
    "    \"\"\"\n",
    "    Convierte una matriz CSR de Scipy a un SparseTensor de PyTorch.\n",
    "    Usa torch.sparse_coo_tensor para evitar advertencias de depreciaci贸n.\n",
    "    \"\"\"\n",
    "    coo = csr_matrix.tocoo()\n",
    "    indices = torch.LongTensor(np.vstack((coo.row, coo.col)))\n",
    "    values = torch.FloatTensor(coo.data)\n",
    "    shape = torch.Size(coo.shape)\n",
    "    return torch.sparse_coo_tensor(indices, values, shape)\n",
    "\n",
    "\n",
    "def normalize_sparse_adjacency_matrix(adj_matrix, alpha):\n",
    "    \"\"\"\n",
    "    Normalizaci贸n sim茅trica asim茅trica: D^-alpha * A * D^-(1-alpha)\n",
    "    Optimizado para operaciones ralas en PyTorch.\n",
    "    \"\"\"\n",
    "    # Suma de filas y columnas usando mm rala\n",
    "    # Creamos un vector de unos en el dispositivo de la matriz\n",
    "    ones_col = torch.ones((adj_matrix.shape[1], 1), device=adj_matrix.device)\n",
    "    ones_row = torch.ones((adj_matrix.shape[0], 1), device=adj_matrix.device)\n",
    "    \n",
    "    rowsum = torch.sparse.mm(adj_matrix, ones_col).squeeze()\n",
    "    colsum = torch.sparse.mm(adj_matrix.t(), ones_row).squeeze()\n",
    "\n",
    "    # Calcular inversas con potencias\n",
    "    d_inv_rows = torch.pow(rowsum, -alpha)\n",
    "    d_inv_rows[torch.isinf(d_inv_rows)] = 0.0\n",
    "    \n",
    "    d_inv_cols = torch.pow(colsum, alpha - 1)\n",
    "    d_inv_cols[torch.isinf(d_inv_cols)] = 0.0\n",
    "\n",
    "    # Crear matrices diagonales ralas\n",
    "    size_r = rowsum.size(0)\n",
    "    idx_r = torch.arange(size_r, device=adj_matrix.device).repeat(2, 1)\n",
    "    d_mat_rows = torch.sparse_coo_tensor(idx_r, d_inv_rows, (size_r, size_r))\n",
    "    \n",
    "    size_c = colsum.size(0)\n",
    "    idx_c = torch.arange(size_c, device=adj_matrix.device).repeat(2, 1)\n",
    "    d_mat_cols = torch.sparse_coo_tensor(idx_c, d_inv_cols, (size_c, size_c))\n",
    "\n",
    "    # Normalizaci贸n: D_r * A * D_c\n",
    "    # Nota: .mm en tensores ralos solo funciona con el primer argumento ralo y el segundo denso, \n",
    "    # o usando torch.sparse.mm. Para ralo-ralo se usa torch.sparse.mm\n",
    "    norm_adj = torch.sparse.mm(d_mat_rows, adj_matrix)\n",
    "    norm_adj = torch.sparse.mm(norm_adj, d_mat_cols)\n",
    "\n",
    "    return norm_adj\n",
    "\n",
    "\n",
    "def min_max_normalize(tensor):\n",
    "    min_val = tensor.min()\n",
    "    max_val = tensor.max()\n",
    "    if max_val - min_val == 0:\n",
    "        return tensor\n",
    "    return (tensor - min_val) / (max_val - min_val)\n",
    "\n",
    "# --- Funciones auxiliares adicionales si se requieren ---\n",
    "\n",
    "def top_k(S, k=1):\n",
    "    \"\"\"Retorna los valores y los 铆ndices de las top-k recomendaciones.\"\"\"\n",
    "    return torch.topk(S, k, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fb301f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import scipy.sparse as sp\n",
    "import os\n",
    "import gc\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def run_tuning():\n",
    "    dataset = \"latam\"\n",
    "    batch_size = 500  \n",
    "    sample_size = 20000\n",
    "    \n",
    "    print(f\" Iniciando Afinamiento (Modo GPU-TopK Optimizado)\")\n",
    "    \n",
    "    # 1. Cargar Matrices\n",
    "    sp_tr = sp.load_npz(f\"dataset/{dataset}_train.npz\")\n",
    "    sp_val = sp.load_npz(f\"dataset/{dataset}_val.npz\")\n",
    "    num_total_authors = sp_tr.shape[0]\n",
    "\n",
    "    np.random.seed(42)\n",
    "    sample_indices = np.random.choice(num_total_authors, sample_size, replace=False)\n",
    "    sample_indices.sort() \n",
    "\n",
    "    # Cargar matriz rala base y mover a GPU\n",
    "    R_tr_gpu = csr2torch(sp_tr).to(device).float()\n",
    "\n",
    "    configs = [(a, f) for a in [0.4, 0.5, 0.6, 0.7] for f in [1, 2, 3]]\n",
    "    best_recall = 0\n",
    "    best_params = None\n",
    "\n",
    "    print(f\"\\n{'Alpha':<7} | {'Filtro':<7} | {'Recall@20':<10} | {'NDCG@20':<10}\")\n",
    "    print(\"-\" * 55)\n",
    "\n",
    "    for alpha, filt in configs:\n",
    "        # Normalizaci贸n\n",
    "        R_norm = normalize_sparse_adjacency_matrix(R_tr_gpu, alpha).float()\n",
    "        R_norm_T = R_norm.t()\n",
    "\n",
    "        total_recall = 0\n",
    "        total_ndcg = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(0, sample_size, batch_size):\n",
    "                start = i\n",
    "                end = min(i + batch_size, sample_size)\n",
    "                curr_idx = sample_indices[start:end]\n",
    "                \n",
    "                # 1. Batch denso de entrenamiento para el c谩lculo\n",
    "                R_batch_dense = torch.from_numpy(sp_tr[curr_idx].toarray()).to(device).float()\n",
    "                \n",
    "                # 2. Operaciones TurboCF (Proyecci贸n Asociativa)\n",
    "                p1 = torch.sparse.mm(R_norm_T, R_batch_dense.t()).t()\n",
    "                p2 = torch.sparse.mm(R_norm, p1.t()).t()\n",
    "\n",
    "                if filt == 1:\n",
    "                    batch_res = p2\n",
    "                elif filt == 2:\n",
    "                    p2_p = torch.sparse.mm(R_norm_T, p2.t()).t()\n",
    "                    p2_p = torch.sparse.mm(R_norm, p2_p.t()).t()\n",
    "                    batch_res = 2 * p2 - p2_p\n",
    "                elif filt == 3:\n",
    "                    p2_f = torch.sparse.mm(R_norm_T, p2.t()).t()\n",
    "                    p2_f = torch.sparse.mm(R_norm, p2_f.t()).t()\n",
    "                    p3_f = torch.sparse.mm(R_norm_T, p2_f.t()).t()\n",
    "                    p3_f = torch.sparse.mm(R_norm, p3_f.t()).t()\n",
    "                    batch_res = p2 + 0.01 * (-p3_f + 10*p2_f - 29*p2)\n",
    "\n",
    "                # 3. Masking: Penalizar 铆tems ya vistos en entrenamiento\n",
    "                batch_res.sub_(R_batch_dense * 1e9) \n",
    "                \n",
    "                # 4. EXTRACCIN TOP-K EN GPU (Esto arregla el 0.0000 y da velocidad)\n",
    "                _, top_indices = torch.topk(batch_res, k=20, dim=1)\n",
    "                preds_indices = top_indices.cpu().numpy()\n",
    "                \n",
    "                # 5. Ground Truth Ralo para evaluaci贸n r谩pida\n",
    "                gt_batch_sparse = sp_val[curr_idx]\n",
    "                \n",
    "                # 6. Evaluaci贸n usando las funciones optimizadas\n",
    "                total_recall += recall_at_k(gt_batch_sparse, preds_indices, k=20) * (end - start)\n",
    "                total_ndcg += ndcg_at_k(gt_batch_sparse, preds_indices, k=20) * (end - start)\n",
    "                \n",
    "                # Limpieza de temporales del batch\n",
    "                del R_batch_dense, batch_res, p1, p2\n",
    "                if 'p2_p' in locals(): del p2_p\n",
    "                if 'p2_f' in locals(): del p2_f\n",
    "                if 'p3_f' in locals(): del p3_f\n",
    "                \n",
    "                if (i // batch_size) % 10 == 0:\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "        cur_recall = total_recall / sample_size\n",
    "        cur_ndcg = total_ndcg / sample_size\n",
    "\n",
    "        print(f\"{alpha:<7.2f} | {filt:<7} | {cur_recall:<10.4f} | {cur_ndcg:<10.4f}\")\n",
    "\n",
    "        if cur_recall > best_recall:\n",
    "            best_recall = cur_recall\n",
    "            best_params = (alpha, filt)\n",
    "\n",
    "        del R_norm, R_norm_T\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"-\" * 55)\n",
    "    print(f\" Ganador: Alpha={best_params[0]}, Filtro={best_params[1]}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf155c2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Configurar dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def run_final_evaluation():\n",
    "    # --- CONFIGURACIN ---\n",
    "    dataset = \"latam\"\n",
    "    batch_size = 500\n",
    "    # Usa los mejores par谩metros que obtuviste en el tuning\n",
    "    best_alpha = 0.40  \n",
    "    best_filter = 2\n",
    "    top_k_save = 100 # Cu谩ntas recomendaciones guardar para tu plataforma\n",
    "    \n",
    "    print(f\" Iniciando Evaluaci贸n Final y Generaci贸n de Activos (Alpha={best_alpha}, Filtro={best_filter})\")\n",
    "    \n",
    "    # 1. Carga y Uni贸n de Datos (Train + Val para entrenar el modelo final)\n",
    "    sp_tr = sp.load_npz(f\"dataset/{dataset}_train.npz\")\n",
    "    sp_val = sp.load_npz(f\"dataset/{dataset}_val.npz\")\n",
    "    sp_test = sp.load_npz(f\"dataset/{dataset}_test.npz\") # Conjunto para m茅trica final\n",
    "\n",
    "    sp_final_train = sp_tr + sp_val \n",
    "    num_authors = sp_final_train.shape[0]\n",
    "\n",
    "    # Mover matriz rala de entrenamiento a GPU\n",
    "    R_final_tr_gpu = csr2torch(sp_final_train).to(device).float()\n",
    "    \n",
    "    # 2. Normalizaci贸n de Grafo\n",
    "    print(\" Generando Normalizaci贸n de Grafo...\")\n",
    "    R_norm = normalize_sparse_adjacency_matrix(R_final_tr_gpu, best_alpha).float()\n",
    "    R_norm_T = R_norm.t()\n",
    "\n",
    "    # Preparar contenedores para exportar a la API\n",
    "    final_indices = np.zeros((num_authors, top_k_save), dtype=np.int32)\n",
    "    \n",
    "    total_recall_test = 0\n",
    "    total_ndcg_test = 0\n",
    "    valid_users_test = 0\n",
    "\n",
    "    print(f\" Procesando {num_authors:,} autores...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, num_authors, batch_size):\n",
    "            start = i\n",
    "            end = min(i + batch_size, num_authors)\n",
    "            \n",
    "            # Batch denso de la matriz de entrenamiento final\n",
    "            R_batch_dense = torch.from_numpy(sp_final_train[start:end].toarray()).to(device).float()\n",
    "            \n",
    "            # --- OPERACIONES TURBOCF (ASOCIATIVAS) ---\n",
    "            # En lugar de usar P, usamos R_norm y R_norm_T secuencialmente\n",
    "            p1 = torch.sparse.mm(R_norm_T, R_batch_dense.t()).t()\n",
    "            p2 = torch.sparse.mm(R_norm, p1.t()).t()\n",
    "\n",
    "            if best_filter == 1:\n",
    "                batch_res = p2\n",
    "            elif best_filter == 2:\n",
    "                p2_p = torch.sparse.mm(R_norm_T, p2.t()).t()\n",
    "                p2_p = torch.sparse.mm(R_norm, p2_p.t()).t()\n",
    "                batch_res = 2 * p2 - p2_p\n",
    "            elif best_filter == 3:\n",
    "                p2_f = torch.sparse.mm(R_norm_T, p2.t()).t()\n",
    "                p2_f = torch.sparse.mm(R_norm, p2_f.t()).t()\n",
    "                p3_f = torch.sparse.mm(R_norm_T, p2_f.t()).t()\n",
    "                p3_f = torch.sparse.mm(R_norm, p3_f.t()).t()\n",
    "                batch_res = p2 + 0.01 * (-p3_f + 10*p2_f - 29*p2)\n",
    "\n",
    "            # Masking: No recomendar lo que ya existe en train+val\n",
    "            batch_res.sub_(R_batch_dense * 1e9)\n",
    "            \n",
    "            # Extraer Top-K\n",
    "            _, top_indices = torch.topk(batch_res, k=top_k_save, dim=1)\n",
    "            preds_indices_np = top_indices.cpu().numpy()\n",
    "            \n",
    "            # Guardar para la API (los 100 mejores)\n",
    "            final_indices[start:end] = preds_indices_np\n",
    "            \n",
    "            # Evaluaci贸n sobre el Test Set (M茅trica Real de la Tesis)\n",
    "            gt_test_batch = sp_test[start:end]\n",
    "            # Solo evaluamos si el usuario tiene algo en el test set\n",
    "            total_recall_test += recall_at_k(gt_test_batch, preds_indices_np, k=20) * (end - start)\n",
    "            total_ndcg_test += ndcg_at_k(gt_test_batch, preds_indices_np, k=20) * (end - start)\n",
    "\n",
    "            # Limpieza\n",
    "            del R_batch_dense, batch_res, p1, p2\n",
    "            if 'p2_p' in locals(): del p2_p\n",
    "            if 'p2_f' in locals(): del p2_f\n",
    "            if 'p3_f' in locals(): del p3_f\n",
    "            \n",
    "            if i % (batch_size * 20) == 0:\n",
    "                print(f\"Progreso: {i/num_authors*100:.1f}%\")\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    # 3. Reporte Final de Tesis\n",
    "    final_recall = total_recall_test / num_authors\n",
    "    final_ndcg = total_ndcg_test / num_authors\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(f\" RESULTADOS FINALES SOBRE TEST SET\")\n",
    "    print(f\"Recall@20: {final_recall:.4f}\")\n",
    "    print(f\"NDCG@20:   {final_ndcg:.4f}\")\n",
    "    print(\"=\"*30)\n",
    "\n",
    "    # 4. Guardar archivos para la API / Sistema\n",
    "    output_path = \"prod_assets\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    np.save(f\"{output_path}/turbocf_recs_idx.npy\", final_indices)\n",
    "    print(f\" Activos guardados en '{output_path}/'. 隆Listo para producci贸n!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_final_evaluation()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

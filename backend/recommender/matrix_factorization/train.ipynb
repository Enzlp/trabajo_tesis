{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbdf006",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Instalaci√≥n de dependencias necesarias en Colab\n",
    "!pip install implicit -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966dba05",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Optimizaci√≥n de fragmentaci√≥n de memoria CUDA\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1. PREPARACI√ìN Y FILTRADO\n",
    "# ---------------------------------------------------------------\n",
    "def preprocess_data(df_pairs):\n",
    "    print(\"üîç Filtrando autores con al menos 2 colaboraciones...\")\n",
    "    counts = pd.concat([df_pairs['pair_min'], df_pairs['pair_max']]).value_counts()\n",
    "    eligible_authors = counts[counts >= 2].index\n",
    "\n",
    "    df_filtered = df_pairs[\n",
    "        df_pairs['pair_min'].isin(eligible_authors) &\n",
    "        df_pairs['pair_max'].isin(eligible_authors)\n",
    "    ].copy()\n",
    "\n",
    "    print(f\"‚úÖ Autores elegibles: {len(eligible_authors):,}\")\n",
    "    print(f\"‚úÖ Interacciones resultantes: {len(df_filtered):,}\")\n",
    "    return df_filtered\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2. SPLIT LOO TRIPLE\n",
    "# ---------------------------------------------------------------\n",
    "def triple_loo_split(df, seed=42):\n",
    "    print(\"‚úÇÔ∏è Generando Split LOO (Train/Val/Test)...\")\n",
    "    rng = np.random.default_rng(seed)\n",
    "    adj = defaultdict(list)\n",
    "    for idx, row in enumerate(df.itertuples()):\n",
    "        adj[row.pair_min].append(idx)\n",
    "        adj[row.pair_max].append(idx)\n",
    "\n",
    "    test_idx, val_idx, assigned = set(), set(), set()\n",
    "\n",
    "    for author in adj:\n",
    "        indices = [i for i in adj[author] if i not in assigned]\n",
    "        if len(indices) >= 3:\n",
    "            rng.shuffle(indices)\n",
    "            test_idx.add(indices[0])\n",
    "            val_idx.add(indices[1])\n",
    "            assigned.update([indices[0], indices[1]])\n",
    "        elif len(indices) == 2:\n",
    "            t = rng.choice(indices)\n",
    "            test_idx.add(t)\n",
    "            assigned.add(t)\n",
    "\n",
    "    all_indices = np.arange(len(df))\n",
    "    train_idx = np.setdiff1d(all_indices, list(test_idx | val_idx))\n",
    "\n",
    "    return df.iloc[train_idx], df.iloc[list(val_idx)], df.iloc[list(test_idx)]\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 3. M√âTRICAS VECTORIZADAS (CON FIX OOM)\n",
    "# ---------------------------------------------------------------\n",
    "def calculate_metrics_batch(U, R_train, R_target, users_to_eval, item_popularity, total_authors, K=20, batch_size=5000):\n",
    "    \"\"\"\n",
    "    Evaluaci√≥n en GPU. batch_size reducido a 500 para evitar OutOfMemory.\n",
    "    \"\"\"\n",
    "    u_tensor = torch.from_numpy(U).cuda()\n",
    "    recall_list, ndcg_list = [], []\n",
    "    recommended_items_all = set()\n",
    "    novelty_sum = 0.0\n",
    "\n",
    "    total_train_interactions = sum(item_popularity.values())\n",
    "\n",
    "    # Pre-calcular log2 para NDCG\n",
    "    log2_ranks = np.log2(np.arange(K) + 2)\n",
    "\n",
    "    for i in range(0, len(users_to_eval), batch_size):\n",
    "        batch_idx = users_to_eval[i:i + batch_size]\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            # C√°lculo de similitud: (Batch x Factors) @ (Factors x Total)\n",
    "            scores = torch.matmul(u_tensor[batch_idx], u_tensor.t())\n",
    "            scores_cpu = scores.cpu().numpy()\n",
    "            del scores # Liberar memoria GPU inmediatamente\n",
    "\n",
    "        for idx, u_idx in enumerate(batch_idx):\n",
    "            u_scores = scores_cpu[idx]\n",
    "\n",
    "            # Filtro: ya vistos y self\n",
    "            seen = R_train.getrow(u_idx).indices\n",
    "            u_scores[seen] = -1e10\n",
    "            u_scores[u_idx] = -1e10\n",
    "\n",
    "            # Top-K\n",
    "            idx_part = np.argpartition(-u_scores, K - 1)[:K]\n",
    "            preds = idx_part[np.argsort(-u_scores[idx_part])]\n",
    "\n",
    "            recommended_items_all.update(preds)\n",
    "\n",
    "            # Novelty\n",
    "            u_nov = sum([-np.log2(item_popularity.get(p, 1)/total_train_interactions) for p in preds])\n",
    "            novelty_sum += (u_nov / K)\n",
    "\n",
    "            # Recall & NDCG\n",
    "            target_indices = R_target.getrow(u_idx).indices\n",
    "            hits_mask = np.isin(preds, target_indices)\n",
    "            hits_count = np.sum(hits_mask)\n",
    "\n",
    "            recall_list.append(hits_count / len(target_indices))\n",
    "\n",
    "            if hits_count > 0:\n",
    "                dcg = np.sum(1.0 / log2_ranks[hits_mask])\n",
    "                idcg = np.sum(1.0 / log2_ranks[:min(len(target_indices), K)])\n",
    "                ndcg_list.append(dcg / idcg)\n",
    "            else:\n",
    "                ndcg_list.append(0.0)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    del u_tensor\n",
    "    return {\n",
    "        \"recall\": np.mean(recall_list),\n",
    "        \"ndcg\": np.mean(ndcg_list),\n",
    "        \"coverage\": len(recommended_items_all) / total_authors,\n",
    "        \"novelty\": novelty_sum / len(users_to_eval)\n",
    "    }\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 4. ENTRENAMIENTO ALS\n",
    "# ---------------------------------------------------------------\n",
    "def train_mf_optimized(R_train, factors, reg, alpha, iterations=20):\n",
    "    R_conf = (R_train * alpha).astype(np.float32)\n",
    "    model = AlternatingLeastSquares(\n",
    "        factors=factors, regularization=reg, iterations=iterations,\n",
    "        use_gpu=True, random_state=42\n",
    "    )\n",
    "    model.fit(R_conf.tocsr().T, show_progress=False)\n",
    "\n",
    "    P, Q = model.user_factors, model.item_factors\n",
    "    if not isinstance(P, np.ndarray):\n",
    "        P, Q = P.to_numpy(), Q.to_numpy()\n",
    "\n",
    "    U = (P + Q) / 2.0\n",
    "    norms = np.linalg.norm(U, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = 1e-10\n",
    "    return (U / norms).astype(np.float32)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5. PIPELINE PRINCIPAL\n",
    "# ---------------------------------------------------------------\n",
    "def run_experiment(df_raw, author_to_idx):\n",
    "    df_filtered = preprocess_data(df_raw)\n",
    "    df_train, df_val, df_test = triple_loo_split(df_filtered)\n",
    "\n",
    "    n_authors = len(author_to_idx)\n",
    "\n",
    "    def to_csr(df):\n",
    "        r = df['pair_min'].map(author_to_idx).values\n",
    "        c = df['pair_max'].map(author_to_idx).values\n",
    "        data = np.ones(len(r))\n",
    "        rows = np.concatenate([r, c]); cols = np.concatenate([c, r])\n",
    "        d = np.concatenate([data, data])\n",
    "        return csr_matrix((d, (rows, cols)), shape=(n_authors, n_authors))\n",
    "\n",
    "    R_train = to_csr(df_train)\n",
    "    R_val = to_csr(df_val)\n",
    "    R_test = to_csr(df_test)\n",
    "\n",
    "    train_counts = pd.concat([df_train['pair_min'], df_train['pair_max']]).map(author_to_idx).value_counts().to_dict()\n",
    "\n",
    "    # --- FASE 1: GRID SEARCH (20,000 Autores) ---\n",
    "    print(\"\\nüîç FASE 1: Tuning con muestra de 20k autores...\")\n",
    "    val_users = np.where(R_val.getnnz(axis=1) > 0)[0]\n",
    "    sample_val = np.random.choice(val_users, min(20000, len(val_users)), replace=False)\n",
    "\n",
    "    best_ndcg = -1\n",
    "    best_params = {}\n",
    "\n",
    "    for f in [128, 256]:\n",
    "        for a in [10, 40]:\n",
    "            for r in [0.01, 0.1, 1.0]: # Regularizaci√≥n a√±adida\n",
    "                t0 = time.time()\n",
    "                U = train_mf_optimized(R_train, factors=f, reg=r, alpha=a, iterations=15)\n",
    "                m = calculate_metrics_batch(U, R_train, R_val, sample_val, train_counts, n_authors)\n",
    "\n",
    "                print(f\"Factors: {f} | Alpha: {a} | Reg: {r} -> NDCG: {m['ndcg']:.4f} | Recall: {m['recall']:.4f} ({time.time()-t0:.1f}s)\")\n",
    "\n",
    "                if m['ndcg'] > best_ndcg:\n",
    "                    best_ndcg = m['ndcg']\n",
    "                    best_params = {'factors': f, 'alpha': a, 'reg': r}\n",
    "\n",
    "                # Limpieza estricta de memoria en cada iteraci√≥n del grid\n",
    "                del U\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    # --- FASE 2: EVALUACI√ìN FINAL EN TEST ---\n",
    "    print(f\"\\nüèÜ FASE 2: Evaluaci√≥n Final con par√°metros {best_params}...\")\n",
    "    R_train_full = R_train + R_val\n",
    "    full_counts = pd.concat([df_train, df_val])[['pair_min', 'pair_max']].stack().map(author_to_idx).value_counts().to_dict()\n",
    "\n",
    "    U_final = train_mf_optimized(R_train_full, **best_params, iterations=30)\n",
    "\n",
    "    test_users = np.where(R_test.getnnz(axis=1) > 0)[0]\n",
    "    print(f\"üìä Evaluando {len(test_users):,} autores en Test...\")\n",
    "\n",
    "    final_m = calculate_metrics_batch(U_final, R_train_full, R_test, test_users, full_counts, n_authors)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üéØ RESULTADOS FINALES EN TEST (LOO)\")\n",
    "    print(f\"Recall@20:   {final_m['recall']:.6f}\")\n",
    "    print(f\"NDCG@20:     {final_m['ndcg']:.6f}\")\n",
    "    print(f\"Coverage:    {final_m['coverage']:.6f}\")\n",
    "    print(f\"Novelty:     {final_m['novelty']:.6f}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Cargar datos\n",
    "    df_path = \"data/df_pairs_unique.pkl\"\n",
    "    a2idx_path = \"data/author_to_idx.npy\"\n",
    "\n",
    "    if os.path.exists(df_path) and os.path.exists(a2idx_path):\n",
    "        df_pairs_unique = pd.read_pickle(df_path)\n",
    "        author2idx = np.load(a2idx_path, allow_pickle=True).item()\n",
    "        run_experiment(df_pairs_unique, author2idx)\n",
    "    else:\n",
    "        print(\"‚ùå Error: No se encontraron los archivos de datos.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
